{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29f62d9f-5ed4-4e9a-b539-94e797a14a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 00:48:43,216 - modelscope - INFO - PyTorch version 1.8.1 Found.\n",
      "2023-05-10 00:48:43,218 - modelscope - INFO - Loading ast index from /home/yangwenhao/.cache/modelscope/ast_indexer\n",
      "2023-05-10 00:48:43,279 - modelscope - INFO - Loading done! Current index file version is 1.5.2, with md5 c5a43dc1cfbe78c3cd5963d04e20ef8f and a total number of 860 components indexed\n"
     ]
    }
   ],
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24409ed5-d30a-42ed-a514-3d0c1ce3141f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 00:48:44,788 - modelscope - INFO - initiate model from damo/speech_paraformer_asr_nat-zh-cn-16k-common-vocab8358-tensorflow1\n",
      "2023-05-10 00:48:44,790 - modelscope - INFO - initiate model from location damo/speech_paraformer_asr_nat-zh-cn-16k-common-vocab8358-tensorflow1.\n",
      "2023-05-10 00:48:44,794 - modelscope - INFO - initialize model from damo/speech_paraformer_asr_nat-zh-cn-16k-common-vocab8358-tensorflow1\n",
      "2023-05-10 00:48:44,797 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2023-05-10 00:48:44,797 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2023-05-10 00:48:44,798 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'damo/speech_paraformer_asr_nat-zh-cn-16k-common-vocab8358-tensorflow1'}. trying to build by task and model information.\n",
      "2023-05-10 00:48:44,798 - modelscope - WARNING - No preprocessor key ('generic-asr', 'auto-speech-recognition') found in PREPROCESSOR_MAP, skip building preprocessor.\n"
     ]
    }
   ],
   "source": [
    "inference_pipeline = pipeline(\n",
    "    task=Tasks.auto_speech_recognition,\n",
    "    model='damo/speech_paraformer_asr_nat-zh-cn-16k-common-vocab8358-tensorflow1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bbc616-751e-453d-85fd-398d1ac696e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_pipeline = pipeline(\n",
    "    task=Tasks.auto_speech_recognition,\n",
    "    model='damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch',\n",
    "    vad_model='damo/speech_fsmn_vad_zh-cn-16k-common-pytorch',\n",
    "    punc_model='damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118d7818-166f-4dee-a975-c1934d4c10e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_result = inference_pipeline(audio_in='../mipi/20230510000744.wav')\n",
    "print(rec_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af951d31-a0f5-49a2-b159-9cfb76e2fd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41f895ae-4d57-4c58-aa20-77bc78aa6b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "song = AudioSegment.from_file('../mipi/20230510000744.aac')\n",
    "song.export(\"../mipi/20230510000744.wav\", format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3e49563-c8df-4b58-972f-c36b45ffa474",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam, sr = sf.read('../mipi/20230510000744.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ff49550-3a14-422b-90ce-d48375a26a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19488768, 2)\n"
     ]
    }
   ],
   "source": [
    "seg = int(len(sam)/20)\n",
    "print(sam.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96ae441c-cf0a-40ea-b837-8e1ca2ac68ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 01:31:34,884 - modelscope - INFO - Decoding with pcm files ...\n",
      "2023-05-12 01:31:34,884 (asr_inference_pipeline:514) INFO: Decoding with pcm files ...\n",
      "2023-05-12 01:31:35,068 - modelscope - INFO - Computing the result of ASR ...\n",
      "2023-05-12 01:31:35,068 (asr_inference_pipeline:549) INFO: Computing the result of ASR ...\n"
     ]
    }
   ],
   "source": [
    "rec_result = inference_pipeline(audio_in=sam[:64000, 1])['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae2942cf-1844-4116-9e76-2c92e8a1f2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'喂，后面是。'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4adfddff-de7c-4c1e-b868-b9670b6c3e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-12 00:06:54,368 - modelscope - INFO - Decoding with pcm files ...\n",
      "2023-05-12 00:06:54,368 (asr_inference_pipeline:514) INFO: Decoding with pcm files ...\n",
      "2023-05-12 00:06:57,198 - modelscope - INFO - Computing the result of ASR ...\n",
      "2023-05-12 00:06:57,198 (asr_inference_pipeline:549) INFO: Computing the result of ASR ...\n",
      "2023-05-12 00:06:57,448 - modelscope - INFO - Decoding with pcm files ...\n",
      "2023-05-12 00:06:57,448 (asr_inference_pipeline:514) INFO: Decoding with pcm files ...\n",
      "2023-05-12 00:06:58,327 - modelscope - INFO - Computing the result of ASR ...\n",
      "2023-05-12 00:06:58,327 (asr_inference_pipeline:549) INFO: Computing the result of ASR ...\n",
      "2023-05-12 00:06:58,373 - modelscope - INFO - Decoding with pcm files ...\n",
      "2023-05-12 00:06:58,373 (asr_inference_pipeline:514) INFO: Decoding with pcm files ...\n",
      "2023-05-12 00:06:59,091 - modelscope - INFO - Computing the result of ASR ...\n",
      "2023-05-12 00:06:59,091 (asr_inference_pipeline:549) INFO: Computing the result of ASR ...\n",
      "2023-05-12 00:06:59,230 - modelscope - INFO - Decoding with pcm files ...\n",
      "2023-05-12 00:06:59,230 (asr_inference_pipeline:514) INFO: Decoding with pcm files ...\n",
      "2023-05-12 00:07:00,077 - modelscope - INFO - Computing the result of ASR ...\n",
      "2023-05-12 00:07:00,077 (asr_inference_pipeline:549) INFO: Computing the result of ASR ...\n",
      "2023-05-12 00:07:00,292 - modelscope - INFO - Decoding with pcm files ...\n",
      "2023-05-12 00:07:00,292 (asr_inference_pipeline:514) INFO: Decoding with pcm files ...\n",
      "2023-05-12 00:07:01,212 - modelscope - INFO - Computing the result of ASR ...\n",
      "2023-05-12 00:07:01,212 (asr_inference_pipeline:549) INFO: Computing the result of ASR ...\n",
      "2023-05-12 00:07:01,598 - modelscope - INFO - Decoding with pcm files ...\n",
      "2023-05-12 00:07:01,598 (asr_inference_pipeline:514) INFO: Decoding with pcm files ...\n",
      "2023-05-12 00:07:02,527 - modelscope - INFO - Computing the result of ASR ...\n",
      "2023-05-12 00:07:02,527 (asr_inference_pipeline:549) INFO: Computing the result of ASR ...\n",
      "2023-05-12 00:07:02,905 - modelscope - INFO - Decoding with pcm files ...\n",
      "2023-05-12 00:07:02,905 (asr_inference_pipeline:514) INFO: Decoding with pcm files ...\n",
      "2023-05-12 00:07:03,598 - modelscope - INFO - Computing the result of ASR ...\n",
      "2023-05-12 00:07:03,598 (asr_inference_pipeline:549) INFO: Computing the result of ASR ...\n",
      "2023-05-12 00:07:03,977 - modelscope - INFO - Decoding with pcm files ...\n",
      "2023-05-12 00:07:03,977 (asr_inference_pipeline:514) INFO: Decoding with pcm files ...\n",
      "2023-05-12 00:07:04,987 - modelscope - INFO - Computing the result of ASR ...\n",
      "2023-05-12 00:07:04,987 (asr_inference_pipeline:549) INFO: Computing the result of ASR ...\n",
      "2023-05-12 00:07:05,370 - modelscope - INFO - Decoding with pcm files ...\n",
      "2023-05-12 00:07:05,370 (asr_inference_pipeline:514) INFO: Decoding with pcm files ...\n",
      "2023-05-12 00:07:06,337 - modelscope - INFO - Computing the result of ASR ...\n",
      "2023-05-12 00:07:06,337 (asr_inference_pipeline:549) INFO: Computing the result of ASR ...\n",
      "2023-05-12 00:07:06,606 - modelscope - INFO - Decoding with pcm files ...\n",
      "2023-05-12 00:07:06,606 (asr_inference_pipeline:514) INFO: Decoding with pcm files ...\n",
      "2023-05-12 00:07:07,622 - modelscope - INFO - Computing the result of ASR ...\n",
      "2023-05-12 00:07:07,622 (asr_inference_pipeline:549) INFO: Computing the result of ASR ...\n",
      "2023-05-12 00:07:07,667 - modelscope - INFO - Decoding with pcm files ...\n",
      "2023-05-12 00:07:07,667 (asr_inference_pipeline:514) INFO: Decoding with pcm files ...\n",
      "2023-05-12 00:07:08,550 - modelscope - INFO - Computing the result of ASR ...\n",
      "2023-05-12 00:07:08,550 (asr_inference_pipeline:549) INFO: Computing the result of ASR ...\n",
      "2023-05-12 00:07:08,595 - modelscope - INFO - Decoding with pcm files ...\n",
      "2023-05-12 00:07:08,595 (asr_inference_pipeline:514) INFO: Decoding with pcm files ...\n",
      "2023-05-12 00:07:09,560 - modelscope - INFO - Computing the result of ASR ...\n",
      "2023-05-12 00:07:09,560 (asr_inference_pipeline:549) INFO: Computing the result of ASR ...\n",
      "2023-05-12 00:07:09,606 - modelscope - INFO - Decoding with pcm files ...\n",
      "2023-05-12 00:07:09,606 (asr_inference_pipeline:514) INFO: Decoding with pcm files ...\n",
      "2023-05-12 00:07:10,596 - modelscope - INFO - Computing the result of ASR ...\n",
      "2023-05-12 00:07:10,596 (asr_inference_pipeline:549) INFO: Computing the result of ASR ...\n",
      "2023-05-12 00:07:10,731 - modelscope - INFO - Decoding with pcm files ...\n",
      "2023-05-12 00:07:10,731 (asr_inference_pipeline:514) INFO: Decoding with pcm files ...\n",
      "2023-05-12 00:07:11,533 - modelscope - INFO - Computing the result of ASR ...\n",
      "2023-05-12 00:07:11,533 (asr_inference_pipeline:549) INFO: Computing the result of ASR ...\n",
      "2023-05-12 00:07:11,676 - modelscope - INFO - Decoding with pcm files ...\n",
      "2023-05-12 00:07:11,676 (asr_inference_pipeline:514) INFO: Decoding with pcm files ...\n",
      "2023-05-12 00:07:12,511 - modelscope - INFO - Computing the result of ASR ...\n",
      "2023-05-12 00:07:12,511 (asr_inference_pipeline:549) INFO: Computing the result of ASR ...\n",
      "2023-05-12 00:07:12,896 - modelscope - INFO - Decoding with pcm files ...\n",
      "2023-05-12 00:07:12,896 (asr_inference_pipeline:514) INFO: Decoding with pcm files ...\n",
      "2023-05-12 00:07:13,645 - modelscope - INFO - Computing the result of ASR ...\n",
      "2023-05-12 00:07:13,645 (asr_inference_pipeline:549) INFO: Computing the result of ASR ...\n",
      "2023-05-12 00:07:13,990 - modelscope - INFO - Decoding with pcm files ...\n",
      "2023-05-12 00:07:13,990 (asr_inference_pipeline:514) INFO: Decoding with pcm files ...\n",
      "2023-05-12 00:07:14,819 - modelscope - INFO - Computing the result of ASR ...\n",
      "2023-05-12 00:07:14,819 (asr_inference_pipeline:549) INFO: Computing the result of ASR ...\n",
      "2023-05-12 00:07:15,160 - modelscope - INFO - Decoding with pcm files ...\n",
      "2023-05-12 00:07:15,160 (asr_inference_pipeline:514) INFO: Decoding with pcm files ...\n",
      "2023-05-12 00:07:16,107 - modelscope - INFO - Computing the result of ASR ...\n",
      "2023-05-12 00:07:16,107 (asr_inference_pipeline:549) INFO: Computing the result of ASR ...\n",
      "2023-05-12 00:07:16,344 - modelscope - INFO - Decoding with pcm files ...\n",
      "2023-05-12 00:07:16,344 (asr_inference_pipeline:514) INFO: Decoding with pcm files ...\n",
      "2023-05-12 00:07:17,191 - modelscope - INFO - Computing the result of ASR ...\n",
      "2023-05-12 00:07:17,191 (asr_inference_pipeline:549) INFO: Computing the result of ASR ...\n",
      "2023-05-12 00:07:17,581 - modelscope - INFO - Decoding with pcm files ...\n",
      "2023-05-12 00:07:17,581 (asr_inference_pipeline:514) INFO: Decoding with pcm files ...\n",
      "2023-05-12 00:07:18,414 - modelscope - INFO - Computing the result of ASR ...\n",
      "2023-05-12 00:07:18,414 (asr_inference_pipeline:549) INFO: Computing the result of ASR ...\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in range(20):\n",
    "    start = i*seg\n",
    "    end = start + seg\n",
    "    sample = sam[start:end].mean(axis=1)\n",
    "    rec_result = inference_pipeline(audio_in=sample)\n",
    "    result.append(rec_result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f079ddd-18d3-4d5e-b543-dceefd8f698a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = \"\".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71653c7e-0b51-4e48-beba-7c1012092476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'喂，嗯，听得到，哎，没有，我先跟你解释解释吧。嗯，怎么说呢？我觉得这次要说两个点，第一个点是关于上次的，就我也不知道你是怎么认为的啊，或者你是什么体验啊，可能可能体验没有，那么就是你的对我的回应可能没有那么好。嗯，然后我要告诉你，原因原因是因为他很在意，说你给我发消息太多了，然后觉得好像你这个有点分享日常那种性质，所以不太，所以他有点在意，他觉得不太好。嗯，然后我就我就在中间很难办，嗯，因为我觉得啊。就是你知道这是什么问题吗？就是这种事情，就是他觉得这样不好，但是我觉得呢嗯我也不知道你怎么觉得的啊，反正我觉得呢就是嗯可以发，只要不发的那么频繁，就是什么的也还行。我不知道你怎么看的。然后我就想着，因为他比较在意嘛，嗯怎么说呢？我觉得如果单从我的角度来看，我觉得他确实有嗯过度紧张的嫌疑，但是我也能够就是换位思考一下，对吧？如果是我的话，嗯，如果我如果我是个女生，有个男有个女生，天天给我的男朋友发消息，什么什么她说的啊啊，就这种东西他的意思是说他也会挺在意的，所以我才会这样。然后为什么我上次那样回呢？其实我挺纠结的，因为你给我发那个就是那个。头发的照片儿的时候，他就跟我我我当时我我我本来觉得就有点，我当时看着是有点害怕啊，因为我想着我们也没聊什么奇怪的内容，然后我就把他然然后我当时看着不是挺害怕的嘛，然后我就把那个图截了个图发给他了，我说这谁谁谁发了一个什么图图吓死我了。然后他就觉得他觉得你这个你这个发这个东西有点奇怪，然后我细想，我确实觉得奇怪，为什么觉得奇怪呢？就是因为你不是在床上嘛，对吧？然后你发了一下头发的照片，然后我觉得确实不太好。因为女孩子嘛又不是男生什么的，就是你要非说他百分之百没有问题，我觉得也说不好，你要说有问题吧，好像又没有那么严重，就看谁的心理状态。就是如果你要单论我来说，我觉得没有问题，就是有问题也很小，我可以忽略不计，但是在他眼。那就比较严，就比较严重，你懂我意思吗？嗯，好了啊，那你是希望怎样？然后这就是上次的事情，我我我我我觉得这也算是给你一个解释吧。就然后这么说吧，我会这么发，其实就是就很像我觉得这个东西我当时发这个东西就很像我之前给你分享那种心态的，完全我敢保证一点，可能一点别的什么都没有，可能也没有考虑到说要不是你跟我说当时在床上这个问题，我都没有想过，我都没有想到这个点，我完全是没有想到这个点的。然后还有就是哎我觉得然后啊，然后你这是这是第一。一个第一个问题啊，我不知道你怎么看啊，当时就这样啊，那你的你你你是希望怎样啊？没有，我就是说这是我之前的反应，就是我为什么会这样，我给你解释一下，就如果你觉得不舒服什么的，可能是我确实没有处理太好，我当时也没有，那么就是周翔的懂吗？给你一回没有，我现在不，我现在想想，好像怪我吧。然后第二点就是他觉得因为他之前就跟我说过，你你记得之前吗？我也跟你说过，他就是说他说希望我们不要聊的那么频繁，就是不要那么日常，不要发太多，日常他觉得有点不喜欢我这个。觉得我到了理解，但是然后还有意思呢，然后然后这件事情还要怪我，这是怪我，为什么呢？他之前不是玩游戏吗？然后我在想犹豫这件事情，要不要说嗯，你说吧，反正就是怪我，嗯，他觉得我骗了他就之前不是我们一起玩游戏嘛，因为之前那谁不玩，你知道吧？就以前那谁不玩儿，然后他玩，然后他不是玩儿游戏嘛，刚玩游戏就是刚我们在一起那会儿玩游戏的时候，然后他就问我，呃，然后刚好是过什么节啊，还是什么时候来着，然后我送了他一个皮肤，嗯，然后他就然后他就问我是不是还送过你皮肤，是不是还送过其他人皮肤？然后我当时我就觉得我要是说我送过你。或者我送过别人什么的，那他妈的他肯定又不开心。然后我就觉得我本来也就是当时的心态，我也就是觉得哎送一个皮肤就皮肤呗，就大家开心就行嘛，我也没当什么奇怪的懂吗？就是我没把这个送皮肤这个当成多么奇怪的，什么情感表示什么的。然后他好像是什么时候去玩我的号，发现我给你送过皮肤，然后他就很生气。他说我在骗他这个这个我我觉得还是赖我啊，这这这确实赖我，然后他就觉得这件事情又让他觉得的有危机感，觉得我们俩有问题，要不然你就答应后面，要不你就当以后没有这个朋友了吧，然后然后那个。这样吧，我那天就就就挺难过我，我就为什么不舒服，就我觉得就你心里已经选择。哎呀，我不知道没有，我觉得这嗯没有，其实我想说什么呢？我觉得哎我也不知道，我觉得这事儿我处理的不好，因为这事儿不是我一个人能决定的就懂吗？我觉得这这这这这这这我不知道该怎么办，就是有人让我二选一，你选他吧。没有，我希望是我们能做，就是我们可以什么，只不过是就是不要那么频繁嘛，有事儿说嘛就。我觉得这样可以接，这样其实也还行。他是什么时候跟你说这些话的，就我那天那个头发之后嘛，前几天就上周末，我不知道那个头发啥时候忘记了，我也不知道哪一天五一五一之前吗？那你五一就不该再给我发那些东西以后，慢慢就习惯对，反正他觉得哎我也不知道这这这这我然后我在想一个问题，是不是我哎我题外话啊，是我的错觉吗？我怎么感觉我这老师在退让呢？我已经退无可退了，我不知道。没有，我就是觉得什么吧，如果他真的很东方卫视，我只能说换位思考他的所有他所有顾虑他他那些其实我都能理解。如果因为如果换成是我自己，我也会嗯哼嗯是啊，但是这但是但是有一种感觉，就是哎我也不知道，就就就反正我我我只能说这这这我不知道，哎，我只能我我我好像只能做取舍，就是就是本来说好的，我觉得我们两人可能当很好的朋友的，但是只能当普通朋友没有办法，那你删我微信吧，游戏可以是你自己决定吧。没有，他说的是可以不删，但是只要不出现这种问题就行。我当我当初之所以在第一次那个情况下，我同意第二次押回来。嗯，主要是因为我真的特别珍惜，然后现在就像就已经让我觉得已经没有没有那个，反正上次那个我就我就有有点感觉到了，那就没有必要了，就已经不是我我原来原来我们我们那种关系了，已经不是那样子了。嗯，哼可能吧，我不知道是不是，反正我。我就觉得，所以那那天那句，但是口气也不是很合适，说你变了这句话，但是确实是我觉得我我感受到了最继续的嗨切没有，就我也不知道我我只能说什么呢？抱歉，这怎么办？行吧？我就想说这些对，还有一个小事，我还忘了，我应该不会删啊。首先我说清楚啊，我应该不会删啊，请。到了吗？喂音为什么不会酸音，为什么不会酸？没有，我觉得这也不一定就是难，难道朋友都都是要那种两肋插刀什么的人吗？我觉得也可以当就是普通朋友也行啊，就大家多一个认识的人吗？没有必要做的那么绝。我觉得是啊，还有一个我想到了一个点，我不能删的原因，你小子没有那个也没关系，因为因为支付宝还在嘛，我刚刚就想跟你说，这个那个也没关啊，对，你什么时候还钱，你小子能不能你能不能再缓两个月？哎，花儿，你一共借了多少，我都忘了一两千多万，还是一千多两次两次哦，就就微信接过一次，然后。嗯，这个这个领导不用担心，其实是可能最近没有我嗯，这个不管你删不删，只要那个支付宝还在，我肯定会会给你的。嗯，知道了。虽然有这些这些不愉快，但是这个起码你应该相信我没有，我只是不知道，我觉得我这个人是什么呢？是有疑虑呢啊什么不？我说我这个人是对各种可能性都什么的，就是你不要介意啊。对，所有人我都会这样，就是知道，那那不然还是等我给你之后再删吧。没有没有没有没有我我我我的意思说这个东西倒没跟跟那个挂钩就没有关系嗯。行吧行吧啊，真的都过自己的生活去吧。一天那么忙，我觉得我这段时间都很忙，感觉你也挺忙。对行吧，你有什么还有什么想说的吗？就挺后悔的吧。后悔啥就感觉我应该是真的在你这里真把你当成很在意的朋友，然后大概是我谢谢。哎，本来也没什么，是不是？哎，所以你最近怎么样？我还没问啊，我觉得你不需要知道的。哼哼没有啊，那我想知道嘛，我靠，我感觉我很多事情都跟你说呀，但你又不说，因为我已经不想跟你分享了呀，那你第二次了。行，知道了。还有其实之前他也挺介意的。然后呢，你是怎么做的去，可是大肠，可是我我把我心里真正的想法告诉他呀，在没有他之前，我我就认识你啊，包括我别的朋友啊，最后他全部都接受啊，接受你们你们可以在我心里存在啊，但是这个每当然当然这个每个人做法不一样，这个没什么好对比的喜爱，没有办法，我就可能是因为我没有，那没有那么有耐心，没有。那么好的方法，对我觉得我做不到，让一个人什么好吗？其他就没什么好说了，我就就就怪我自己吧。我之前就觉得可能在你这里我是挺重要的一个位置，大概就会相差了。可能有可能是我自己错觉吧，是好了，没事了，没事了，该干嘛干嘛去吧？唉，行，没事儿，别别不开心啊，过两天就好了。嗯，我确实要我确实很难过，并且是确实刚才有点控制不住自己。哎，行吧？没有，你知道我为什么吗？我觉得我现在已经麻木了，然后我觉得你确实确实对不起我嗯嗯，确实对不起我，我我认为我们的友情确实对不起我嗯，确实很抱歉。行吧，那你睡吧，没事了吧，就我觉得很奇怪，突然奇不飘飘一句道歉，就让我觉得好像之前跟我认识的那个，你根本就不是你。睡吧睡吧睡吧，没有，就哎，我只想告诉你这种事情没有没有那么容易的，只是嘴上说的清清楚罢了。好的好的，没有，这对我来说也不容易，可能吧。西行，我去睡吧，睡了再见，拜拜，不建议嗯。'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b19ded06-943e-4aef-b846-8d9b27234e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 00:52:40,863 - modelscope - INFO - Use user-specified model revision: v1.1.7\n",
      "2023-05-10 00:52:40,863 (api:470) INFO: Use user-specified model revision: v1.1.7\n",
      "2023-05-10 00:52:41,194 - modelscope - INFO - initiate model from /home/yangwenhao/.cache/modelscope/hub/damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch\n",
      "2023-05-10 00:52:41,194 (base:49) INFO: initiate model from /home/yangwenhao/.cache/modelscope/hub/damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch\n",
      "2023-05-10 00:52:41,198 - modelscope - INFO - initiate model from location /home/yangwenhao/.cache/modelscope/hub/damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch.\n",
      "2023-05-10 00:52:41,198 (base:51) INFO: initiate model from location /home/yangwenhao/.cache/modelscope/hub/damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch.\n",
      "2023-05-10 00:52:41,201 - modelscope - INFO - initialize model from /home/yangwenhao/.cache/modelscope/hub/damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch\n",
      "2023-05-10 00:52:41,201 (base_model:118) INFO: initialize model from /home/yangwenhao/.cache/modelscope/hub/damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch\n",
      "2023-05-10 00:52:41,204 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2023-05-10 00:52:41,204 (base:283) WARNING: No preprocessor field found in cfg.\n",
      "2023-05-10 00:52:41,205 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2023-05-10 00:52:41,205 (base:292) WARNING: No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2023-05-10 00:52:41,205 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/home/yangwenhao/.cache/modelscope/hub/damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch'}. trying to build by task and model information.\n",
      "2023-05-10 00:52:41,205 (base:311) WARNING: Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/home/yangwenhao/.cache/modelscope/hub/damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch'}. trying to build by task and model information.\n",
      "2023-05-10 00:52:41,205 - modelscope - WARNING - No preprocessor key ('generic-punc', 'punctuation') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "2023-05-10 00:52:41,205 (base:325) WARNING: No preprocessor key ('generic-punc', 'punctuation') found in PREPROCESSOR_MAP, skip building preprocessor.\n"
     ]
    }
   ],
   "source": [
    "word_refine_pipline = pipeline(\n",
    "    task=Tasks.punctuation,\n",
    "    model='damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch',\n",
    "    vad_model='damo/speech_fsmn_vad_zh-cn-16k-common-pytorch',\n",
    "    punc_model='damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch',\n",
    "    model_revision=\"v1.1.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e72a38e-016b-47c2-b344-8e76f7c4761c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 00:53:20,272 - modelscope - INFO - Punctuation Processing: 嗯听得到嗯嗯嗯嗯嗯嗯哎嗯好了那也是希望怎样这么说吧我会这么发其实就是就很像我觉得这个东西我当时发这个东西就很像我之前跟你分享那种心态的完全我敢保证一点可能一点别的什么都没有可能也没有考虑到说要不是你跟我说当时在床上这个问题我都没有想过我都没有想到这个点我完全是没有想到这个点的但是他嗯当时就这年了那你的你你是希望望望怎样啊没有我现在通过我现在想想好像我吧大概是我自己行吧还得怎么了嗯你说吧嗯什么呢要不你就当以后面要不你就当以后没有这个朋友了吧然后然后那个这样样吧我那天就就就挺难过我我就为什么不舒服就我觉得就你心里已经选择哎呀我知知道不觉得他是什么时候跟你说这些话的就我那天那个头发之后嘛我不知道那个头发啥时候忘记了我也不知道哪一天五一五一之前吗那你五一就不该再给我发那些东西以后慢慢就习惯忘记了我只能说换位思我只能说换位思考他的所有他所有顾虑他他那些其实我都能理解如果因为如果换成是我自己我也会可以也可以只我都我微信吧游戏也可以自己决定吧不需要我当我当初之所以在第一次那个情况下我同意第二次压回来主要是因为我真的特别珍惜然后现在就上就已经让我觉得已经没有没有那个反正上次那个我就我就有有点感觉到了反正没们必要了就已经不是我原来反正我们我们那种关系了已经不是那样子了反正上次是不是反正我是觉得所以那那天那句那个口气也不是很合适说你变了这句话但是确实是我觉得我我感受到了这个因为什么不会删因为什么不会删没有那个也没关系因为因为支付宝还在嘛我刚刚就想跟你说这个那个也没关系能不能能不能再还两个月没次两次就就微信接过一次呢这个这个你倒不用担心其实是可最近这个不管你删不删只要那个支付宝还在我肯定会会给你的虽然有这些这些不愉快但是这个起码你应该相信我啊什么嗯知道那那不然还是等我给你之后再删吧就挺后悔的吧就我感觉我应该是真的在你这里真把你当成很在意的朋友就大概是我好了你没什么我觉得你不需要指导了我觉觉得不不想跟你分享了呀我没什么了还有其实之前他也挺接受啊可是他成可是我我把我心里真正的想法告诉他呀在没有他之前我我就认识你啊包括别的朋友了最后他全部都接受啊接受你们你们可以在我心里存在啊最后他接受每当然当然这个每个人做法不一样这个没什么好对比的但只能我只能说我说我只能说其他就没什么好事了我就就就在我自己吧我自己就觉得可能在你这里我是挺重要的一个位置大概就会相差了可能可能是我自己错觉了吧可能没事了事事哎干嘛干嘛去吧挺重差就好了我确实有我确实很难过并且是干自己吧我挺控制住自己然后我觉得你确实确实对不起我确实对不起我我我认为我们的友情确实对不起我就我觉得很奇怪突然然飘飘飘一道道歉让我觉得好像之前跟我认识的那个你跟我就不是你睡吧睡吧睡吧有这样吧可能吧不是吧我睡吧 ...\n",
      "2023-05-10 00:53:20,272 (punctuation_processing_pipeline:150) INFO: Punctuation Processing: 嗯听得到嗯嗯嗯嗯嗯嗯哎嗯好了那也是希望怎样这么说吧我会这么发其实就是就很像我觉得这个东西我当时发这个东西就很像我之前跟你分享那种心态的完全我敢保证一点可能一点别的什么都没有可能也没有考虑到说要不是你跟我说当时在床上这个问题我都没有想过我都没有想到这个点我完全是没有想到这个点的但是他嗯当时就这年了那你的你你是希望望望怎样啊没有我现在通过我现在想想好像我吧大概是我自己行吧还得怎么了嗯你说吧嗯什么呢要不你就当以后面要不你就当以后没有这个朋友了吧然后然后那个这样样吧我那天就就就挺难过我我就为什么不舒服就我觉得就你心里已经选择哎呀我知知道不觉得他是什么时候跟你说这些话的就我那天那个头发之后嘛我不知道那个头发啥时候忘记了我也不知道哪一天五一五一之前吗那你五一就不该再给我发那些东西以后慢慢就习惯忘记了我只能说换位思我只能说换位思考他的所有他所有顾虑他他那些其实我都能理解如果因为如果换成是我自己我也会可以也可以只我都我微信吧游戏也可以自己决定吧不需要我当我当初之所以在第一次那个情况下我同意第二次压回来主要是因为我真的特别珍惜然后现在就上就已经让我觉得已经没有没有那个反正上次那个我就我就有有点感觉到了反正没们必要了就已经不是我原来反正我们我们那种关系了已经不是那样子了反正上次是不是反正我是觉得所以那那天那句那个口气也不是很合适说你变了这句话但是确实是我觉得我我感受到了这个因为什么不会删因为什么不会删没有那个也没关系因为因为支付宝还在嘛我刚刚就想跟你说这个那个也没关系能不能能不能再还两个月没次两次就就微信接过一次呢这个这个你倒不用担心其实是可最近这个不管你删不删只要那个支付宝还在我肯定会会给你的虽然有这些这些不愉快但是这个起码你应该相信我啊什么嗯知道那那不然还是等我给你之后再删吧就挺后悔的吧就我感觉我应该是真的在你这里真把你当成很在意的朋友就大概是我好了你没什么我觉得你不需要指导了我觉觉得不不想跟你分享了呀我没什么了还有其实之前他也挺接受啊可是他成可是我我把我心里真正的想法告诉他呀在没有他之前我我就认识你啊包括别的朋友了最后他全部都接受啊接受你们你们可以在我心里存在啊最后他接受每当然当然这个每个人做法不一样这个没什么好对比的但只能我只能说我说我只能说其他就没什么好事了我就就就在我自己吧我自己就觉得可能在你这里我是挺重要的一个位置大概就会相差了可能可能是我自己错觉了吧可能没事了事事哎干嘛干嘛去吧挺重差就好了我确实有我确实很难过并且是干自己吧我挺控制住自己然后我觉得你确实确实对不起我确实对不起我我我认为我们的友情确实对不起我就我觉得很奇怪突然然飘飘飘一道道歉让我觉得好像之前跟我认识的那个你跟我就不是你睡吧睡吧睡吧有这样吧可能吧不是吧我睡吧 ...\n"
     ]
    }
   ],
   "source": [
    "results_p = word_refine_pipline(text_in=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7363955d-74de-483a-a457-65e0cfe29d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '嗯，听得到。嗯嗯嗯嗯嗯嗯，哎嗯，好了，那也是希望怎样这么说吧，我会这么发，其实就是就很像我觉得这个东西我当时发这个东西就很像我之前跟你分享那种心态的，完全我敢保证一点，可能一点别的什么都没有，可能也没有考虑到说要不是你跟我说当时在床上这个问题，我都没有想过，我都没有想到这个点，我完全是没有想到这个点的。但是他嗯当时就这年了，那你的你你是希望望望怎样啊？没有，我现在通过，我现在想想，好像我吧，大概是我自己行吧，还得怎么了。嗯，你说吧嗯什么呢？要不你就当以后面，要不你就当以后没有这个朋友了吧。然后然后那个这样样吧，我那天就就就挺难过我，我就为什么不舒服，就我觉得就你心里已经选择。哎呀，我知知道不觉得他是什么时候跟你说这些话的，就我那天那个头发之后嘛，我不知道那个头发啥时候忘记了，我也不知道哪一天五一五一之前吗？那你五一就不该再给我发那些东西以后，慢慢就习惯忘记了。我只能说换位思，我只能说换位思考他的所有他所有顾虑他他那些其实我都能理解。如果因为如果换成是我自己，我也会可以，也可以，只我都我微信吧，游戏也可以自己决定吧，不需要我。当我当初之所以在第一次那个情况下，我同意第二次压回来，主要是因为我真的特别珍惜，然后现在就上就已经让我觉得已经没有没有那个，反正上次那个我就我就有有点感觉到了，反正没们必要了，就已经不是我原来反正我们我们那种关系了，已经不是那样子了，反正上次是不是？反正我是觉得。所以那那天那句那个口气也不是很合适，说你变了这句话，但是确实是我觉得我我感受到了这个，因为什么不会删，因为什么不会删，没有那个也没关系，因为因为支付宝还在嘛，我刚刚就想跟你说，这个那个也没关系，能不能能不能再还两个月，没次两次就就微信接过一次呢。这个这个你倒不用担心，其实是可最近这个不管你删不删，只要那个支付宝还在，我肯定会会给你的。虽然有这些这些不愉快，但是这个起码你应该相信我啊什么嗯，知道，那那不然还是等我给你之后再删吧，就挺后悔的吧。就我感觉我应该是真的在你这里真把你当成很在意的朋友，就大概是我好了。你没什么，我觉得你不需要指导了，我觉觉得不不想跟你分享了呀，我没什么了。还有其实之前他也挺接受啊，可是他成可是我我把我心里真正的想法告诉他呀，在没有他之前我我就认识你啊，包括别的朋友了，最后他全部都接受啊，接受你们你们可以在我心里存在啊，最后他接受每当然当然这个每个人做法不一样，这个没什么好对比的。但只能我只能说，我说我只能说其他就没什么好事了，我就就就在我自己吧，我自己就觉得可能在你这里我是挺重要的一个位置，大概就会相差了。可能可能是我自己错觉了吧，可能没事了，事事哎，干嘛干嘛去吧，挺重差就好了。我确实有我确实很难过，并且是干自己吧，我挺控制住自己。然后我觉得你确实确实对不起，我确实对不起我我我认为我们的友情确实对不起，我就我觉得很奇怪，突然然飘飘飘一道道歉，让我觉得好像之前跟我认识的那个，你跟我就不是你睡吧，睡吧，睡吧，有这样吧，可能吧，不是吧，我睡吧。'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db66ee58-aa14-4d37-b694-076fccc135a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
